summary(fit)
dislims=range(dis)
dis.grid=seq(from=dislims[1],to=dislims[2])
#we want to make predictions for nox (vs dis)
preds=predict(fit,newdata=list(dis=dis.grid),se=TRUE)
plot(dis,nox,col="darkgrey")
lines(dis.grid,preds$fit,lwd=2,col="blue")
#K fold cross validation
set.seed(2017)
ndegree = 3:13
cv.error=vector(mode="numeric",length=10)
for (d in ndegree){
glm.fit=glm(nox~bs(dis,df=ndegree), data=Boston)
cv.error[d-3]=cv.glm(Boston,glm.fit,K=10)$delta[1]
}
# The plot of the errors
plot(ndegree,cv.error,type="b")
#K fold cross validation
set.seed(2017)
ndegree = 3:13
cv.error=vector(mode="numeric",length=11)
for (d in ndegree){
glm.fit=glm(nox~bs(dis,df=ndegree), data=Boston)
cv.error[d-3]=cv.glm(Boston,glm.fit,K=10)$delta[1]
}
# The plot of the errors
plot(ndegree,cv.error,type="b")
#K fold cross validation
set.seed(2017)
ndegree = 3:13
cv.error=vector(mode="numeric",length=10)
for (d in ndegree){
glm.fit=glm(nox~bs(dis,df=ndegree), data=Boston)
cv.error[d-3]=cv.glm(Boston,glm.fit,K=10)$delta[1]
}
# The plot of the errors
plot(ndegree[1:10],cv.error[1:10],type="b")
require(splines)
fit=lm(nox~bs(dis,df=4, knots = 9.5),data=Boston)
plot(dis,nox,col="darkgrey")
lines(dis.grid,predict(fit,list(dis=dis.grid)),col="darkgreen",lwd=2)
abline(v=9.5,lty=2,col="darkgreen")
require(splines)
fit=lm(nox~bs(dis,df=4, knots = 9),data=Boston)
plot(dis,nox,col="darkgrey")
lines(dis.grid,predict(fit,list(dis=dis.grid)),col="darkgreen",lwd=2)
abline(v=9,lty=2,col="darkgreen")
#reading als data
inDir = "/home/orchisama/Documents/Stanford classes/Stats 216/homework/"
setwd(inDir)
body.env <- environment()
load('body.RData', envir = body.env)
ls()
attach(body.env)
?body
X
X$colName
X$colNames
X[0]
X[:,1]
colnames(X)
colnames(Y)
X[0:50]
X[1:50,:]
X[1:50,]
#dividing into test and training set
train.X = X[1:200,]
train.Y = Y[1:200,]
test.X = X[201:,]
nrow(X)
#dividing into test and training set
train.X = X[0:199,]
train.Y = Y[0:199,]
test.X = X[200:nrow(Y),]
test.Y = Y[200:nrow(Y),]
colnames(Y)
#dividing into test and training set
train.X = X[0:199,]
train.Y = Y[0:199,]
test.X = X[200:nrow(X),]
test.Y = Y[200:nrow(Y),]
library(pls)
install.packages("pls")
#dividing into test and training set
train.X = X[0:199,]
train.Y = Y[0:199,]
test.X = X[200:nrow(X),]
test.Y = Y[200:nrow(Y),]
library(pls)
set.seed(20)
#principal components regression
pcr.fit = pcr(Y$Weight~.data = X, scale = "TRUE", validation = "CV")
#dividing into test and training set
train.X = X[0:199,]
train.Y = Y[0:199,]
test.X = X[200:nrow(X),]
test.Y = Y[200:nrow(Y),]
library(pls)
set.seed(20)
#principal components regression
pcr.fit = pcr(Y$Weight~,data = X, scale = "TRUE", validation = "CV")
#dividing into test and training set
train.X = X[0:199,]
train.Y = Y[0:199,]
test.X = X[200:nrow(X),]
test.Y = Y[200:nrow(Y),]
library(pls)
set.seed(20)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = X, scale = "TRUE", validation = "CV")
summary(pcr.fit)
#dividing into test and training set
train.X = X[0:199,]
train.Y = Y[0:199,]
test.X = X[200:nrow(X),]
test.Y = Y[200:nrow(Y),]
library(pls)
set.seed(20)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = X, subset = train.X, scale = "TRUE", validation = "CV")
nrow(train.X)
ncol(train.X)
nrow(test.X)
#dividing into test and training set
train.X = X[0:200,]
train.Y = Y[0:200,]
test.X = X[201:nrow(X),]
test.Y = Y[201:nrow(Y),]
library(pls)
set.seed(20)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = X, subset = train.X, scale = "TRUE", validation = "CV")
#dividing into test and training set
train.X = X[0:200,]
train.Y = Y[0:200,]
test.X = X[201:nrow(X),]
test.Y = Y[201:nrow(Y),]
library(pls)
set.seed(20)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = X, subset = train.X, scale = TRUE, validation = "CV")
?pcr
#dividing into test and training set
train.X = X[0:200,]
train.Y = Y[0:200,]
test.X = X[201:nrow(X),]
test.Y = Y[201:nrow(Y),]
library(pls)
set.seed(20)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = X, subset = train.Y, scale = TRUE, validation = "CV")
#dividing into test and training set
train.X = X[0:200,]
train.Y = Y[0:200,]
test.X = X[201:nrow(X),]
test.Y = Y[201:nrow(Y),]
library(pls)
set.seed(20)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = X.train, subset = train.Y, scale = TRUE, validation = "CV")
#dividing into test and training set
train.X = X[0:200,]
train.Y = Y[0:200,]
test.X = X[201:nrow(X),]
test.Y = Y[201:nrow(Y),]
library(pls)
set.seed(20)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = train.X, subset = train.Y, scale = TRUE, validation = "CV")
#dividing into test and training set
train.X = X[0:200,]
train.Y = Y[0:200,]
test.X = X[201:nrow(X),]
test.Y = Y[201:nrow(Y),]
library(pls)
set.seed(20)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = Y, subset = train.Y, scale = TRUE, validation = "CV")
fit = lm(Y$Weight~.,data=X,subset=train.Y)
?sample
#dividing into test and training set
#seq(507) creates numbers from 1 to 507
#will sample 200 indexes of observations #randomly without replacement
set.seed(20)
train=sample(seq(507),200,replace=FALSE)
library(pls)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = X, subset = Y[train], scale = TRUE, validation = "CV")
#dividing into test and training set
#seq(507) creates numbers from 1 to 507
#will sample 200 indexes of observations #randomly without replacement
set.seed(20)
train=sample(seq(507),200,replace=FALSE)
library(pls)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = X, subset = Y[train,], scale = TRUE, validation = "CV")
#dividing into test and training set
#seq(507) creates numbers from 1 to 507
#will sample 200 indexes of observations #randomly without replacement
set.seed(20)
train=sample(seq(507),200,replace=FALSE)
library(pls)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = X[train,], scale = TRUE, validation = "CV")
?regsubsets
?regsubset
#dividing into test and training set
#seq(507) creates numbers from 1 to 507
#will sample 200 indexes of observations #randomly without replacement
set.seed(20)
train=sample(seq(507),200,replace=FALSE)
train
library(pls)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = X, subset = Y[train,] scale = TRUE, validation = "CV")
#dividing into test and training set
#seq(507) creates numbers from 1 to 507
#will sample 200 indexes of observations #randomly without replacement
set.seed(20)
train=sample(seq(507),200,replace=FALSE)
train
library(pls)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = X, subset = Y[train,], scale = TRUE, validation = 'CV')
#dividing into test and training set
#seq(507) creates numbers from 1 to 507
#will sample 200 indexes of observations #randomly without replacement
set.seed(20)
train=sample(seq(507),200,replace=FALSE)
train
library(pls)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = X, subset = train, scale = TRUE, validation = 'CV')
summary(pcr.fit)
#dividing into test and training set
#seq(507) creates numbers from 1 to 507
#will sample 200 indexes of observations #randomly without replacement
set.seed(20)
train=sample(seq(507),200,replace=FALSE)
library(pls)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = X, subset = train, scale = TRUE, validation = 'CV')
summary(pcr.fit)
#partial least squares regression
pls.fit = plsr(Y$Weight, data = X, subset = train, scale=TRUE, validation = 'CV')
#dividing into test and training set
#seq(507) creates numbers from 1 to 507
#will sample 200 indexes of observations #randomly without replacement
set.seed(20)
train=sample(seq(507),200,replace=FALSE)
library(pls)
#principal components regression
pcr.fit = pcr(Y$Weight~.,data = X, subset = train, scale = TRUE, validation = 'CV')
summary(pcr.fit)
#partial least squares regression
pls.fit = plsr(Y$Weight~., data = X, subset = train, scale=TRUE, validation = 'CV')
summary(pls.fit)
summary(pcr.fit)
summary(pls.fit)
validationplot(pcr.fit,val.type ="MSEP")
validationplot(plsr.fit, val.type = "MSEP")
validationplot(pcr.fit,val.type ="MSEP")
validationplot(pls.fit, val.type = "MSEP")
par(mfrow=c(2,1))
validationplot(pcr.fit,val.type ="MSEP")
par(mfrow=c(2,1))
validationplot(pcr.fit,val.type ="MSEP")
validationplot(pls.fit, val.type = "MSEP")
par(mfrow=c(2,1))
validationplot(pcr.fit,val.type ="MSEP")
validationplot(pls.fit, val.type = "MSEP")
validationplot(pcr.fit,val.type ="MSEP")
validationplot(pls.fit, val.type = "MSEP")
par(mfrow=c(2,1))
validationplot(pcr.fit,val.type ="MSEP")
validationplot(pls.fit, val.type = "MSEP")
par(mfrow=c(2,1))
validationplot(pcr.fit,val.type ="MSEP")
pcr.fit$CV
validationplot(pls.fit, val.type = "MSEP")
pcr.fit$CV
?validationplot
par(mfrow=c(2,1))
validationplot(pcr.fit,val.type ="MSEP")
pcr.fit$CV
validationplot(pls.fit, val.type = "MSEP")
par(mfrow=c(2,1))
validationplot(pcr.fit[1:21],val.type ="MSEP")
par(mfrow=c(2,1))
validationplot(pcr.fit[1:21,],val.type ="MSEP")
pcr.fit
help pcr.fit
?pcr.fit
?pcr
pcr.fit$validation
#using lasso for dimensionality reduction
library{glmnet}
#using lasso for dimensionality reduction
library(glmnet)
x = model.matrix(Y$Weight~., data = X)
y = Y$Weight
lasso.tr=glmnet(x[train,],y[train])
lasso.tr
?predict
pcr.pred = predict(pcr.fit, x[-train ,] , ncomp =10)
pcr.pred = predict(pcr.fit, x[-train,] , ncomp =10)
pcr.pred = predict(pcr.fit, X[-train,] , ncomp =10)
mean((pcr.pred - y$Weight[-train])^2)
pcr.pred = predict(pcr.fit, X[-train,] , ncomp =10)
mean((pcr.pred - Y$Weight[-train])^2)
pcr.pred = predict(pcr.fit, X[-train,] , ncomp =10)
mean((pcr.pred - Y$Weight[-train])^2)
pls.pred = predict(pls.fit,X[-train,], ncomp = 3)
mean((pls.pred - Y$Weight[-train])^2)
#using lasso for dimensionality reduction
library(glmnet)
x = model.matrix(Y$Weight~., data = X)
y = Y$Weight
lasso.tr=glmnet(x[train,],y[train])
plot(lasso.tr,xvar="lambda",label=TRUE)
cv.lasso=cv.glmnet(x[train,],y[train,])
#using lasso for dimensionality reduction
library(glmnet)
x = model.matrix(Y$Weight~., data = X)
y = Y$Weight
lasso.tr=glmnet(x[train,],y[train,])
#using lasso for dimensionality reduction
library(glmnet)
x = model.matrix(Y$Weight~., data = X)
y = Y$Weight
lasso.tr=glmnet(x[train,],y[train])
plot(lasso.tr,xvar="lambda",label=TRUE)
cv.lasso=cv.glmnet(x[train,],y[train])
plot(cv.lasso)
coef(cv.lasso)
#using lasso for dimensionality reduction
library(glmnet)
x = model.matrix(Y$Weight~., data = X)
y = Y$Weight
set.seed(900)
cv.lasso=cv.glmnet(x[train,],y[train])
plot(cv.lasso)
bestlam = cv.lasso$lambda.min
lasso.tr=glmnet(x[train,],y[train])
plot(lasso.tr,xvar="lambda",label=TRUE)
pcr.pred = predict(pcr.fit, X[-train,] , ncomp =10)
mean((pcr.pred - Y$Weight[-train])^2)
pls.pred = predict(pls.fit,X[-train,], ncomp = 3)
mean((pls.pred - Y$Weight[-train])^2)
lasso.pred = predict(lasso.tr,s=bestlam,newx = x[-train,])
mean((lasso.pred - y[-train])^2)
install.packages("e1071")
?svm
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
inDir = "/home/orchisama/Documents/Stanford classes/Stats 216/homework/"
setwd(inDir)
body.env <- environment()
load('body.RData', envir = body.env)
ls()
attach(body.env)
#dividing into test and training set
#seq(507) creates numbers from 1 to 507
#will sample 200 indexes of observations #randomly without replacement
set.seed(20)
train=sample(seq(507),307,replace=FALSE)
train.X <- X[train,]
test.X <- X[-train,]
library(ranger)
bag.mse = vector(mode = "numeric", length = 100)
randf.mse = vector(mode = "numeric", length = 100)
for (i in 1:100){
#predictions using bagging, same function as random   forest, with mtry = all predictor variables
bag.fit = ranger(Y$Weight[train]~.,data=train.X,mtry = ncol(X), num.trees = i)
pred.bag = predict(bag.fit, data = test.X)
bag.mse[i] = mean((pred.bag$predictions - Y$Weight[-train])^2)
#predictions using random forest, mtry taken to be sqrt(p) by default
randf.fit = ranger(Y$Weight[train]~., data=train.X, num.trees = i)
pred.randf = predict(randf.fit, data = test.X)
randf.mse[i] = mean((pred.randf$predictions - Y$Weight[-train])^2)
}
#plot test MSEs vs number of trees
plot(1:100,bag.mse,type = "l",xlab="Number of trees",ylab="Test MSE",col="blue")
lines(1:100,randf.mse,lwd = 1,col="red")
legend("topright", legend = paste(c("Bagging", "Random forests")), pch = 15, col = c("blue","red"))
bag.fit <- ranger(Y$Weight[train]~.,data=train.X,mtry = ncol(X), importance = "permutation")
#see variable importance for bagging
importance(bag.fit)
randf.fit <- ranger(Y$Weight[train]~., data=train.X, importance = "permutation")
#see variable importance for random forests
importance(randf.fit)
randf.fit = ranger(Y$Weight[train]~., data=train.X)
pred.randf = predict(randf.fit, data = test.X)
randf.mse = mean((pred.randf$predictions - Y$Weight[-train])^2)
library(ISLR)
?OJ
set.seed(39)
#attach(OJ)
train = sample(seq(nrow(OJ)), 535, replace = FALSE)
OJ$Purchase <- as.factor(OJ$Purchase)
OJ.train = OJ[train,]
OJ.test = OJ[-train,]
library(e1071)
svmfit = svm(OJ.train$Purchase~., data=OJ.train, kernel="linear", cost=0.05, scale = TRUE)
summary(svmfit)
train.pred = predict(svmfit, OJ.train)
train.mse = mean(train.pred != OJ.train$Purchase)
test.pred = predict(svmfit, OJ.test)
test.mse = mean(test.pred != OJ.test$Purchase)
train.mse
test.mse
set.seed(1)
tune.out = tune(svm, Purchase~., data=OJ.train
,kernel = "linear", ranges = list(cost = c(0.01,0.02,0.03,0.04,0.05,0.1,0.5,2,5,7,10)))
summary(tune.out)
bestmod = tune.out$best.model
train.pred = predict(bestmod,OJ.train)
train.mse = mean(train.pred != OJ.train$Purchase)
test.pred = predict(bestmod, OJ.test)
test.mse = mean(test.pred != OJ.test$Purchase)
train.mse
test.mse
svmfit = svm(OJ.train$Purchase~., data=OJ.train, kernel="radial", cost=0.05, scale = TRUE)
summary(svmfit)
train.pred = predict(svmfit, OJ.train)
train.mse = mean(train.pred != OJ.train$Purchase)
test.pred = predict(svmfit, OJ.test)
test.mse = mean(test.pred != OJ.test$Purchase)
print(train.mse, test.mse)
set.seed(1)
tune.out = tune(svm, Purchase~., data=OJ.train
,kernel = "radial", ranges = list(cost=c(0.01,0.02,0.03,0.04,0.05,0.1,0.5,2,5,7,10)))
summary(tune.out)
bestmod = tune.out$best.model
best.train.pred = predict(bestmod,OJ.train)
best.train.mse = mean(best.train.pred != OJ.train$Purchase)
best.test.pred = predict(bestmod, OJ.test)
best.test.mse = mean(best.test.pred != OJ.test$Purchase)
best.train.mse
best.test.mse
svmfit = svm(OJ.train$Purchase~., data=OJ.train, kernel="poly", degree = 2, cost=0.05, scale = TRUE)
summary(svmfit)
train.pred = predict(svmfit, OJ.train)
train.mse = mean(train.pred != OJ.train$Purchase)
test.pred = predict(svmfit, OJ.test)
test.mse = mean(test.pred != OJ.test$Purchase)
print(train.mse, test.mse)
set.seed(1)
tune.out = tune(svm, Purchase~., data=OJ.train
,kernel = "poly", degree = 2, ranges = list(cost=c(0.01,0.02,0.03,0.04,0.05,0.1,0.5,2,5,7,10)))
summary(tune.out)
bestmod = tune.out$best.model
best.train.pred = predict(bestmod,OJ.train)
best.train.mse = mean(best.train.pred != OJ.train$Purchase)
best.test.pred = predict(bestmod, OJ.test)
best.test.mse = mean(best.test.pred != OJ.test$Purchase)
best.train.mse
best.test.mse
#expand given datasets by including all quadratic and linear interaction terms
#dat <- polym(OJ$WeekofPurcase, OJ$StoreID, OJ$PriceCH, OJ$PriceMM, OJ$DiscCH, OJ$DiscMM,         #OJ$SpecialCH, OJ$SpecialMM, OJ$LoyalCH, OJ$SalePriceMM, OJ$SalePriceCH, OJ$PriceDiff, OJ$Store7, #OJ$PctDiscMM, OJ$PctDiscCH, OJ$ListPriceDiff, OJ$STORE, degree = 2, raw = T)
?svm
?tune
#coef0 term includes all linear and quadratic terms
svmfit = svm(OJ.train$Purchase~., data=OJ.train, kernel="poly", degree = 2, cost=0.05, coef0 = 1,scale = TRUE)
summary(svmfit)
train.pred = predict(svmfit, OJ.train)
train.mse = mean(train.pred != OJ.train$Purchase)
test.pred = predict(svmfit, OJ.test)
test.mse = mean(test.pred != OJ.test$Purchase)
print(train.mse, test.mse)
set.seed(1)
tune.out = tune(svm, Purchase~., data=OJ.train
,kernel = "poly", degree = 2, ranges = list(cost=c(0.01,0.02,0.03,0.04,0.05,0.1,0.5,2,5,7,10)))
summary(tune.out)
bestmod = tune.out$best.model
best.train.pred = predict(bestmod,OJ.train)
best.train.mse = mean(best.train.pred != OJ.train$Purchase)
best.test.pred = predict(bestmod, OJ.test)
best.test.mse = mean(best.test.pred != OJ.test$Purchase)
best.train.mse
best.test.mse
test.mse
train.mse
#coef0 term includes all linear and quadratic terms
svmfit = svm(OJ.train$Purchase~., data=OJ.train, kernel="poly", degree = 2, cost=0.05, coef0 = 1,scale = TRUE)
summary(svmfit)
train.pred = predict(svmfit, OJ.train)
train.mse = mean(train.pred != OJ.train$Purchase)
test.pred = predict(svmfit, OJ.test)
test.mse = mean(test.pred != OJ.test$Purchase)
print(train.mse, test.mse)
set.seed(1)
tune.out = tune(svm, Purchase~., data=OJ.train
,kernel = "poly", degree = 2, coef0 = 1, ranges = list(cost=c(0.01,0.02,0.03,0.04,0.05,0.1,0.5,2,5,7,10)))
summary(tune.out)
bestmod = tune.out$best.model
best.train.pred = predict(bestmod,OJ.train)
best.train.mse = mean(best.train.pred != OJ.train$Purchase)
best.test.pred = predict(bestmod, OJ.test)
best.test.mse = mean(best.test.pred != OJ.test$Purchase)
best.train.mse
best.test.mse
source('~/Documents/Stanford classes/Music 364/final project ideas/Markov_analysis/plotHist.R')
source('~/Documents/Stanford classes/Music 364/final project ideas/Markov_analysis/plotHist.R')
source('~/Documents/Stanford classes/Music 364/final project ideas/Markov_analysis/plotHist.R')
source('~/Documents/Stanford classes/Music 364/final project ideas/Markov_analysis/plotHist.R')
debugSource('~/Documents/Stanford classes/Music 364/final project ideas/Markov_analysis/plotHist.R')
debugSource('~/Documents/Stanford classes/Music 364/final project ideas/Markov_analysis/plotHist.R')
debugSource('~/Documents/Stanford classes/Music 364/final project ideas/Markov_analysis/plotHist.R')
debugSource('~/Documents/Stanford classes/Music 364/final project ideas/Markov_analysis/plotHist.R')
debugSource('~/Documents/Stanford classes/Music 364/final project ideas/Markov_analysis/plotHist.R')
debugSource('~/Documents/Stanford classes/Music 364/final project ideas/Markov_analysis/plotHist.R')
debugSource('~/Documents/Stanford classes/Music 364/final project ideas/Markov_analysis/plotHist.R')
